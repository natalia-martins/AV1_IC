<h1 align="center">
    <a>ğŸ¦– EvoluÃ§Ã£o de Dinossauros no Jogo Dino Game Usando Algoritmos GenÃ©ticos ğŸ¦– </a>
</h1>


### ğŸ”¹ Sobre o projeto
Este projeto utiliza algoritmos genÃ©ticos para treinar dinossauros no jogo Dino Game, simulando a evoluÃ§Ã£o de agentes (dinossauros) ao longo de vÃ¡rias geraÃ§Ãµes para melhorar seu desempenho no jogo.

---

### ğŸ”¹ Objetivo
Evoluir agentes dinossauros para maximizar sua performance no jogo Dino Game ao longo das geraÃ§Ãµes, utilizando os conceitos de **seleÃ§Ã£o natural**, **mutaÃ§Ã£o genÃ©tica** e **crossover** conforme ilustrado nas imagens abaixo:


ğŸ”¸**3Âª GeraÃ§Ã£o:**

![alt text](image-2.png)

ğŸ”¸**7Âª GeraÃ§Ã£o:**

![alt text](image-3.png)

ğŸ”¸**ExibiÃ§Ã£o das informaÃ§Ãµes que acontecem nas partidas:**

![alt text](image-4.png)
![alt text](image-5.png)

---

### ğŸ”¹ Requisitos e InstalaÃ§Ã£o
ğŸ”¸**Requisitos:**
- Python 3
- Bibliotecas necessÃ¡rias:
    - ``` git clone https://github.com/GrupoTuringCodes/chrome-trex-rush ``` 
    - ``` cd chrome-trex-rush  ``` 
    - ``` pip install chrome-trex-rush/  ```

<br>

ğŸ”¸**InstalaÃ§Ã£o:**
1. Clone o repositÃ³rio:
``` github.com/natalia-martins/TrainingTAIC.git ```

---

### ğŸ”¹ Estrutura do Projeto

ğŸ—‚ Abaixo estÃ¡ a estrutura de diretÃ³rios e arquivos do projeto, com uma breve descriÃ§Ã£o de cada componente:

```
.
â”œâ”€â”€ bibliotecas/                             # ContÃ©m mÃ³dulos auxiliares.
â”œâ”€â”€ Dino.py                                  # ImplementaÃ§Ã£o da classe Dino e comportamento do agente.
â”œâ”€â”€ Genetic_Algorithm.py                     # ImplementaÃ§Ã£o dos algoritmos genÃ©ticos (seleÃ§Ã£o, crossover, mutaÃ§Ã£o).
â”œâ”€â”€ Background.py                            # Gerenciamento do cenÃ¡rio do jogo (nuvens, chÃ£o).
â”œâ”€â”€ Brain.py                                 # ImplementaÃ§Ã£o da rede neural (cÃ©rebro) dos dinossauros.
â”œâ”€â”€ Dino_Game.py                             # LÃ³gica principal do jogo Dino Game.
â”œâ”€â”€ Obstacles.py                             # ImplementaÃ§Ã£o dos obstÃ¡culos (cactos, pterossauros).
â”œâ”€â”€ chrome-trex-rush/                        # Biblioteca do jogo base clonada do repositÃ³rio oficial.
â”‚   â””â”€â”€ ...
â”œâ”€â”€ imagens/                                 # ContÃ©m os arquivos de imagem (sprites) usados no jogo.
â”œâ”€â”€ dino_run_0.png                           # Imagem do dinossauro correndo (frame 1).
â”œâ”€â”€ dino_run_1.png                           # Imagem do dinossauro correndo (frame 2).
â”œâ”€â”€ cactus_0.png                             # Imagem de obstÃ¡culo (cacto 1).
â”œâ”€â”€ cactus_1.png                             # Imagem de obstÃ¡culo (cacto 2).
â”œâ”€â”€ cactus_2.png                             # Imagem de obstÃ¡culo (cacto 3).
â”œâ”€â”€ cactus_3.png                             # Imagem de obstÃ¡culo (cacto 4).
â”œâ”€â”€ cactus_4.png                             # Imagem de obstÃ¡culo (cacto 5).
â”œâ”€â”€ cactus_5.png                             # Imagem de obstÃ¡culo (cacto 6).
â”œâ”€â”€ cactus_6.png                             # Imagem de obstÃ¡culo (cacto 7).
â”œâ”€â”€ cactus_7.png                             # Imagem de obstÃ¡culo (cacto 8).
â”œâ”€â”€ cactus_8.png                             # Imagem de obstÃ¡culo (cacto 9).
â”œâ”€â”€ cactus_9.png                             # Imagem de obstÃ¡culo (cacto 10).
â”œâ”€â”€ cactus_10.png                            # Imagem de obstÃ¡culo (cacto 11).
â”œâ”€â”€ cactus_11.png                            # Imagem de obstÃ¡culo (cacto 12).
â”œâ”€â”€ cactus_12.png                            # Imagem de obstÃ¡culo (cacto 13).
â”œâ”€â”€ cactus_13.png                            # Imagem de obstÃ¡culo (cacto 14).
â”œâ”€â”€ cactus_14.png                            # Imagem de obstÃ¡culo (cacto 15).
â”œâ”€â”€ cactus_15.png                            # Imagem de obstÃ¡culo (cacto 16).
â”œâ”€â”€ cloud.png                                # Imagem de nuvem para o cenÃ¡rio.
â”œâ”€â”€ dino_duck_0.png                          # Imagem do dinossauro abaixado (frame 1).
â”œâ”€â”€ dino_duck_1.png                          # Imagem do dinossauro abaixado (frame 2).
â”œâ”€â”€ ground.png                               # Imagem do chÃ£o do jogo.
â”œâ”€â”€ offline-sprite-2x.png                    # Imagem usada como referÃªncia visual no modo offline.
â”œâ”€â”€ ptera_0.png                              # Imagem de obstÃ¡culo (pterossauro, frame 1).
â”œâ”€â”€ ptera_1.png                              # Imagem de obstÃ¡culo (pterossauro, frame 2).
â”œâ”€â”€ Algoritmo_Evolutivo_DinoGame.py          # Algoritmo principal para treinar o dinossauro.
â”œâ”€â”€ Melhor_Dino.py                           # Executa o melhor dinossauro com os pesos salvos.
â”œâ”€â”€ README.md                                # Arquivo de documentaÃ§Ã£o do projeto.
â”œâ”€â”€ Teste.py                                 # Script de teste para verificar o funcionamento.
â”œâ”€â”€ pesos_melhor_individuo.json              # Arquivo JSON contendo os pesos do melhor dinossauro.
```



---

### ğŸ”¹ Algoritmos GenÃ©ticos Utilizados
No projeto, foram utilizados diversos algoritmos genÃ©ticos para evoluir os dinossauros ao longo das geraÃ§Ãµes. 

Os principais sÃ£o:

### **1. SeleÃ§Ã£o Proporcional ao Fitness**

ğŸ”¸ **Como funciona:** 

Utilizamos um algoritmo de seleÃ§Ã£o proporcional ao fitness. Dinossauros com maior pontuaÃ§Ã£o tÃªm mais chances de serem selecionados para reproduÃ§Ã£o. A pontuaÃ§Ã£o de cada dinossauro Ã© elevada ao quadrado para enfatizar a diferenÃ§a entre os mais aptos e os menos aptos.

ğŸ”¸ **CÃ³digo:**
![alt text](image-6.png)

ğŸ”¸ **Diferencial:** 

Testamos outros mÃ©todos de seleÃ§Ã£o, mas a seleÃ§Ã£o proporcional proporcionou uma maior diversidade inicial, garantindo que dinossauros com pequenas vantagens evoluÃ­ssem mais rÃ¡pido.

<br>

### **2. Crossover GenÃ©tico**

ğŸ”¸ **Como funciona:** 

Durante o crossover, genes de dois pais sÃ£o combinados para gerar um novo indivÃ­duo (filho). A chance de herdar genes de um dos pais Ã© controlada por uma porcentagem de heranÃ§a, sorteada aleatoriamente.

ğŸ”¸ **CÃ³digo:**
![alt text](image-7.png)

ğŸ”¸ **Diferencial:** 

O uso de um crossover com variaÃ§Ã£o aleatÃ³ria na heranÃ§a (entre 0% a 100%) garantiu que os indivÃ­duos tivessem uma mistura equilibrada de genes.

<br>

### **3. MutaÃ§Ã£o**

ğŸ”¸ **Como funciona:** 

ApÃ³s o crossover, cada gene pode sofrer mutaÃ§Ã£o com uma taxa de mutaÃ§Ã£o de 5%. A mutaÃ§Ã£o altera aleatoriamente os pesos da rede neural, adicionando variaÃ§Ã£o ao pool genÃ©tico.

ğŸ”¸ **CÃ³digo:**

![alt text](image-8.png)

ğŸ”¸ **Diferencial:** 

Testamos diferentes taxas de mutaÃ§Ã£o. ConcluÃ­mos que uma taxa de 5% com magnitude de 0.1 trouxe o equilÃ­brio ideal entre diversidade e estabilidade no treinamento.

--- 

### ğŸ”¹ Processos de Treinamento

**1. InÃ­cio do Treinamento**
   * O treinamento comeÃ§a com uma populaÃ§Ã£o de dinossauros gerada aleatoriamente. Cada dinossauro tenta pular obstÃ¡culos, e sua performance determina sua pontuaÃ§Ã£o e fitness.

**2. Momento AvanÃ§ado do Treinamento**
   * ApÃ³s vÃ¡rias geraÃ§Ãµes, os dinossauros comeÃ§am a mostrar melhorias significativas. Dinossauros com bom desempenho sobrevivem, e sua inteligÃªncia evolui, ajustando melhor suas aÃ§Ãµes.
  
**3. Melhor IndivÃ­duo**
   * O melhor dinossauro Ã© salvo, com seus pesos sendo armazenados em um arquivo. Ele pode ser carregado posteriormente para testes e comparaÃ§Ãµes.
  
--- 
### ğŸ”¹ Comportamento do CÃ³digo
O cÃ³digo segue o ciclo clÃ¡ssico de um algoritmo genÃ©tico:

  1. **CriaÃ§Ã£o de uma populaÃ§Ã£o inicial** de dinossauros.
   
  2. **AvaliaÃ§Ã£o:** Cada dinossauro joga e acumula uma pontuaÃ§Ã£o.
   
  3. **SeleÃ§Ã£o:** Dinossauros mais aptos sÃ£o selecionados.
   
  4. **ReproduÃ§Ã£o:** Realiza-se crossover e mutaÃ§Ã£o para criar novos dinossauros.
   
  5. **RepetiÃ§Ã£o:** O processo Ã© repetido por vÃ¡rias geraÃ§Ãµes.
   
A cada nova geraÃ§Ã£o, o comportamento do dinossauro melhora Ã  medida que ele se adapta ao ambiente do jogo.

---
### ğŸ”¹ Resultados e Curiosidades

1. **Melhor Algoritmo:** O crossover com taxa de heranÃ§a variÃ¡vel se mostrou mais eficiente do que outros mÃ©todos.
   
2. **Curiosidade:** No inÃ­cio, observamos que a mutaÃ§Ã£o alta atrapalhava a convergÃªncia do treinamento. ApÃ³s ajustar a magnitude da mutaÃ§Ã£o, obtivemos uma evoluÃ§Ã£o mais estÃ¡vel.

3. **Resultado com 1500 pontos:** O dinossauro atingiu uma pontuaÃ§Ã£o superior a 1500, resultado de uma combinaÃ§Ã£o eficaz de estratÃ©gias evolutivas. A utilizaÃ§Ã£o de uma populaÃ§Ã£o relativamente grande, com 200 dinossauros por geraÃ§Ã£o, permitiu uma ampla diversidade genÃ©tica, proporcionando mais oportunidades de encontrar soluÃ§Ãµes eficazes para superar os desafios do jogo. AlÃ©m disso, a taxa de mutaÃ§Ã£o aplicada incentivou a exploraÃ§Ã£o de diferentes possibilidades de comportamento, aumentando a capacidade de adaptaÃ§Ã£o dos dinossauros. Por fim, o processo de reproduÃ§Ã£o, baseado na seleÃ§Ã£o dos dinossauros de maior desempenho a cada geraÃ§Ã£o, garantiu que as caracterÃ­sticas mais adequadas fossem transmitidas, acelerando a evoluÃ§Ã£o ao longo das geraÃ§Ãµes e resultando em uma pontuaÃ§Ã£o elevada.

![1500 pontos](https://github.com/user-attachments/assets/33c0bd84-8378-43dc-b8cb-b0f45790661f)

4. **Resultado com mais de 10000 pontos::** O dinossauro conseguiu superar a pontuaÃ§Ã£o de 10.000 pontos, o que demonstra a eficÃ¡cia das tÃ©cnicas evolutivas aplicadas. O uso de uma populaÃ§Ã£o relativamente grande, com 200 dinossauros por geraÃ§Ã£o, permitiu uma diversidade genÃ©tica significativa, garantindo que diferentes estratÃ©gias fossem testadas e aprimoradas ao longo do tempo. Essa diversidade proporcionou uma maior chance de explorar soluÃ§Ãµes eficientes para enfrentar os obstÃ¡culos do jogo.

    AlÃ©m disso, a taxa de mutaÃ§Ã£o cuidadosamente ajustada foi fundamental para escapar de armadilhas locais, permitindo que o algoritmo evolutivo explorasse novos comportamentos. Essa exploraÃ§Ã£o garantiu que novas variaÃ§Ãµes fossem constantemente       introduzidas no pool genÃ©tico, aumentando a chance de se encontrar comportamentos que maximizassem a sobrevivÃªncia e a pontuaÃ§Ã£o.
    
    O processo de seleÃ§Ã£o natural, que favoreceu os dinossauros com melhor desempenho, garantiu que as caracterÃ­sticas mais bem-sucedidas fossem transmitidas para as geraÃ§Ãµes seguintes. Esse ciclo contÃ­nuo de seleÃ§Ã£o, reproduÃ§Ã£o e mutaÃ§Ã£o, ao          longo de diversas geraÃ§Ãµes, levou Ã  evoluÃ§Ã£o de dinossauros altamente adaptados, resultando em uma pontuaÃ§Ã£o impressionante de 10.000 pontos.
    
    Esses resultados comprovam que a combinaÃ§Ã£o de uma populaÃ§Ã£o diversificada, uma taxa de mutaÃ§Ã£o adequada e uma estratÃ©gia de reproduÃ§Ã£o eficaz foi essencial para alcanÃ§ar esse alto nÃ­vel de desempenho no jogo.
   
![10000 pontos](https://github.com/user-attachments/assets/8c21d1d3-fab4-46cc-bf40-fa1d2f68f8c5)

---

### ğŸ”¹ Salvar e Rodar o Melhor Dinossauro

O melhor dinossauro Ã© salvo automaticamente no arquivo "pesos_melhor_individuo.json" apÃ³s cada geraÃ§Ã£o. 

Para rodar o melhor dinossauro:

![alt text](image-9.png)

Comando:  
-  ```python Melhor_Dino.py ```

---
### ğŸ”¹ VÃ­deos Demonstrativos

ğŸ”¸ **1. InÃ­cio do Treinamento:**

https://github.com/user-attachments/assets/05211b9b-a70b-4084-9baa-d01865ca3170




ğŸ”¸ **2. Momento AvanÃ§ado:**

https://github.com/user-attachments/assets/d713b36f-1b8b-4eed-8890-12751d152bd7





ğŸ”¸ **3. Melhor Dinossauro:**


--- 
### ğŸ”¹ ConclusÃ£o e Aprendizados

- Implementamos algoritmos genÃ©ticos para evoluir dinossauros no jogo T-Rex Rush.

- Primeiro, optamos por utilizar um algoritmo evolutivo baseado em aprendizado por reforÃ§o, devido Ã  sua simplicidade de implementaÃ§Ã£o, mas os resultados obtidos nÃ£o foram satisfatorios.
  
- A mutaÃ§Ã£o e o crossover foram ajustados para melhorar a convergÃªncia e estabilidade.
  
- O uso de uma seleÃ§Ã£o proporcional ao fitness aumentou a diversidade genÃ©tica.

--- 

### ğŸ”¹ Uso
#### ğŸ”¸ ConfiguraÃ§Ã£o Inicial
Antes de rodar o algoritmo genÃ©tico, certifique-se de que a biblioteca chrome-trex-rush estÃ¡ corretamente instalada e configurada. Consulte a [documentaÃ§Ã£o oficial](https://github.com/turing-usp/chrome-trex-rush/blob/master/README.md)  para obter detalhes sobre a configuraÃ§Ã£o.

#### ğŸ”¸ Executando o Algoritmo GenÃ©tico
1. Inicie o processo de treinamento executando o seguinte comando:
``` python src/genetic_algorithm.py ```

2. Durante o treinamento, os agentes evoluirÃ£o com base em uma funÃ§Ã£o de aptidÃ£o, e vocÃª poderÃ¡ observar sua melhoria ao longo das geraÃ§Ãµes.

#### ğŸ”¸ FunÃ§Ãµes Principais
- ``` DinoAgent ```: Classe que representa um dinossauro no jogo T-Rex. Os genes determinam seu comportamento e a funÃ§Ã£o de aptidÃ£o mede seu desempenho.
- ``` genetic_algorithm ```: FunÃ§Ã£o principal que executa o algoritmo genÃ©tico, realizando as operaÃ§Ãµes de seleÃ§Ã£o, cruzamento e mutaÃ§Ã£o.

#### ğŸ”¸ Testes
Para garantir que o cÃ³digo estÃ¡ funcionando corretamente, rode os testes unitÃ¡rios:
``` pytest ```

#### ğŸ”¸ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga os passos abaixo para contribuir:
1. FaÃ§a um fork do repositÃ³rio.
2. Crie uma branch para sua feature ou correÃ§Ã£o.
3. Implemente suas mudanÃ§as e adicione testes (se necessÃ¡rio).
4. Envie um pull request com uma descriÃ§Ã£o clara das modificaÃ§Ãµes.

---

### ğŸ”¹ Links Importantes:
- [Biblioteca chrome-trex-rush](https://github.com/turing-usp/chrome-trex-rush/blob/master/README.md)
- [Template de RepositÃ³rio](https://github.com/ArielMAJ/python-repository-template)

---

### ğŸ”¹ Contato
Para dÃºvidas ou sugestÃµes, entre em contato com:
- ğŸ‘©â€ğŸ’» natalia.santos@aln.senaicimetec.edu.br
- ğŸ‘©ğŸ½â€ğŸ’» nathalia.leite@ba.estudante.senai.br
- ğŸ‘©â€ğŸ’» rafael.matos@aln.senaicimatec.edu.br
<h1 align="center">
